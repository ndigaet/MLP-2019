{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path\n",
    "import keras\n",
    "import numpy as np\n",
    "import time\n",
    "from matplotlib import pyplot as plt\n",
    "from fnn_helper import PlotLosses\n",
    "from MNIST_helper import plot_numbers, visualize_input\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Flatten, Dense, Activation\n",
    "from keras.optimizers import Adam, SGD\n",
    "from keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from fnn_helper import PlotLosses\n",
    "from keras_contrib.callbacks import CyclicLR\n",
    "from matplotlib import pyplot as plt\n",
    "from mlp_helper import plot_confusion_matrix\n",
    "import draw_nn\n",
    "import keras.backend as K\n",
    "if not os.path.exists('mlp_helper.py'):\n",
    "    !wget https://github.com/lab-ml-itba/MLP-2019/raw/master/mlp_helper.py\n",
    "    !wget https://github.com/lab-ml-itba/MLP-2019/raw/master/fnn_helper.py\n",
    "    !wget https://github.com/lab-ml-itba/MLP-2019/raw/master/MNIST_helper.py\n",
    "    !wget https://github.com/lab-ml-itba/MLP-2019/raw/master/draw_nn.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set data: (48000, 28, 28)\n",
      "Training labels: (48000,)\n",
      "\n",
      "CV set data: (12000, 28, 28)\n",
      "CV labels: (12000,)\n",
      "\n",
      "Testing set data: (10000, 28, 28)\n",
      "Testing labels: (10000,)\n"
     ]
    }
   ],
   "source": [
    "(x, y), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# 20% del dataset para validaciÃ³n\n",
    "validation = 0.20\n",
    "N_validation_split = int(x.shape[0]*(1-validation))\n",
    "# Training Set\n",
    "x_train = x[:N_validation_split]\n",
    "y_train = y[:N_validation_split]\n",
    "\n",
    "# Cross Validation Set\n",
    "x_val = x[N_validation_split:]\n",
    "y_val = y[N_validation_split:]\n",
    "print('Training set data:', x_train.shape)\n",
    "print('Training labels:', y_train.shape)\n",
    "print()\n",
    "print('CV set data:', x_val.shape)\n",
    "print('CV labels:', y_val.shape)\n",
    "print()\n",
    "print('Testing set data:',x_test.shape)\n",
    "print('Testing labels:', y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48000, 10)\n",
      "[[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "y_train_categorical = keras.utils.to_categorical(y_train)\n",
    "y_val_categorical = keras.utils.to_categorical(y_val)\n",
    "y_test_categorical = keras.utils.to_categorical(y_test)\n",
    "print(y_train_categorical.shape)\n",
    "print(y_train_categorical[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(units_in_hidden_2=2):\n",
    "    output_size = 10\n",
    "    model_plane = Sequential()\n",
    "    model_plane.add(Flatten(input_shape=x_train.shape[1:]))\n",
    "    model_plane.add(Dense(200, activation='relu',  name='middle1', kernel_initializer='normal'))\n",
    "    # model_plane.add(LeakyReLU())\n",
    "    model_plane.add(Dense(units_in_hidden_2, activation='relu', name='middle2', kernel_initializer='normal'))\n",
    "    # model_plane.add(LeakyReLU())\n",
    "    model_plane.add(Dense(output_size, activation='softmax',  kernel_initializer='normal', name='salida'))\n",
    "    return model_plane"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_20 (Flatten)         (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "middle1 (Dense)              (None, 200)               157000    \n",
      "_________________________________________________________________\n",
      "middle2 (Dense)              (None, 2)                 402       \n",
      "_________________________________________________________________\n",
      "salida (Dense)               (None, 10)                30        \n",
      "=================================================================\n",
      "Total params: 157,432\n",
      "Trainable params: 157,432\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_plane = get_model(2)\n",
    "model_plane.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()\n",
    "batch_size=12\n",
    "lr = 1e-4\n",
    "optim = Adam(lr=lr)\n",
    "units_in_hidden_2 = 2\n",
    "model_plane = get_model(units_in_hidden_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./tb-params-test/Adam_64_0.0001_2_1559849832\n"
     ]
    }
   ],
   "source": [
    "optim_name = str(type(optim)).replace(\"'>\", '').split('.')[-1]\n",
    "log_dir_name = './tb-params-test/'+optim_name+'_'+str(batch_size)+'_'+str(lr)+'_'+str(units_in_hidden_2)+'_'+str(int(time.time()))\n",
    "print(log_dir_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkpointer = ModelCheckpoint(filepath='param-tests.mnist.hdf5', verbose=0, save_best_only=True, mode='max', monitor='val_acc')\n",
    "tbCB = TensorBoard(log_dir=log_dir_name, histogram_freq=1, batch_size=batch_size, write_graph=False, \n",
    "                   write_grads=True, write_images=False, embeddings_freq=0, \n",
    "                   embeddings_layer_names=None, embeddings_metadata=None, embeddings_data=None, \n",
    "                   update_freq='epoch')\n",
    "\n",
    "# clr = CyclicLR(1e-6, 1e-4, 8*int(len(x_train)/batch_size))\n",
    "model_plane.compile(loss = 'categorical_crossentropy', optimizer=optim, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_plane.fit(x_train, \n",
    "          y_train_categorical ,\n",
    "          epochs=100, batch_size=batch_size, \n",
    "          verbose=0, \n",
    "          validation_data=(x_test, y_test_categorical), \n",
    "          callbacks=[tbCB],\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48000/48000 [==============================] - 1s 17us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.02440831386235853, 0.9976458333333333]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_plane.evaluate(x_train, y_train_categorical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 19us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.49745430337451396, 0.9454]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_plane.evaluate(x_test, y_test_categorical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 39us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.44512823535501955, 0.9496]"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model_plane.load_weights('two-layer-2d-leaky-relu.mnist.hdf5')\n",
    "model_plane.load_weights('two-layer-2d-relu.mnist.hdf5')\n",
    "model_plane.evaluate(x_test, y_test_categorical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
